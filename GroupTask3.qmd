---
title: "Group Task 3"
author:
  - name: Yves-Langston Mays
    email: ymmays@cougarnet.uh.edu
    affiliation:
      - name: University of Houston Main Campus
        department: Natural Sciences & Mathematics
        city: Houston
        country: USA
  - name: Uyen Vi Phan
    email: uphan2@uh.edu
    affiliation:
      - name: University of Houston Main Campus
        department: Natural Sciences & Mathematics
        city: Houston
        country: USA
  - name: Author 3
    email: email3@uh.edu
    affiliation:
      - name: University of Houston Main Campus
        department: Natural Sciences & Mathematics
        city: Houston
        country: USA
abstract: |
  Task 3 centers on hurricane risk for 25 cities in the Gulf of Mexico, using data from the Atlantic hurricane database (HURDAT2) from 1851 to 2023, provided by the National Hurricane Center. To analyze and assess this risk, we will perform 3 analyses in R to assess the hurricane risk on the Gulf of Mexico. First, we visualize and note our findings on the storm tracks over the last 25 years (1999-2024), focusing on storm paths, intensity, and duration at each location. Spatial correlation analysis will be used to explore the relationship between hurricane occurrences and contributing environmental factors, while Non-Parametric Density Estimation will estimate location-specific risk based on historical hurricane trajectories. These analyses collectively aim to identify the cities at highest risk of hurricane impact and gauge potential severity. [INSERT FINDINGS OF STUDY]
keywords: [Non-Parametric Density Estimation, Spatial Correlation Analysis, Hurricane Risk Assessment]
format:
  pdf:
    template: GroupTask3.tex
    pdf-engine: lualatex
    keep-tex: true
    toc: true
    number-sections: true
    cite-method: biblatex
bibliography: references.bib
---

\newpage

# Introduction

One of the most common natural disaster plaguing the Gulf of Mexico are Hurricanes. Just this year (2024) there has been 9 hurricanes in the Atlantic Ocean including Beryl, Helen and Milton. These storms can have lasting impacts to people's lives, the environment, infrastructure and to the economy. Since 1980, hurricane damage has costed over \$1.3 trillion in damages with an average of \$22.8 billion dollars per event and 6,890 deaths\[1\]. Learning to predict where, when, and the intensity of hurricanes can not only save us billions of dollars but thousands of lives as well. This is especially important for cities that are at high risk such as cities like New Orleans that exists at extremely low elevations.

This task aims to use historical data on hurricanes to predict future hurricane activity and highlight cities that are at most risk. The historical hurricane data from the National Hurricane Center’s HURDAT2 database, contains hurricane data in the Atlantic from 1851 to 2023. HURDAT2 records the six-hourly information on the location, maximum winds, central pressure, and (beginning in 2004) size of all known tropical cyclones and subtropical cyclones\[2\]. Along with a list of 25 cities and their locations in the Gulf of Mexico, 3 analyses will be performed oh HURDAT2 to analyze and predict the storm tracks in the Gulf of Mexico.

The last 25 (1999-2024) years worth of storm tracks will be first visualized and analyzed on the over the Gulf of Mexico to identify common patterns and trends of the storm tracks. The visualization and the manual analysis provides a good general overview of how these storms move, where they are the most intense, and what places receive the most storms.

The second analysis examines how certain factors like sea surface temperatures and El Nino/La Nina patterns affect hurricane activity. Spatial correlation analysis between these factors and hurricane activity will be used to achieve this. The correlation analysis will show how certain weather phenomena can affect hurricane activity to better predict hurricane activity.

The last analysis uses non-parametric density estimation to assess the hurricane risk based on past trajectories and severity. This can provide insight on where hurricanes are more likely to appear and what routes they take. It can assess what regions will receive the most intense storms. Paired with the spatial correlation analysis, the information provided from the non-parametric density estimation can highlight what cities are most at risk in the Gulf of Mexico.

These 3 analyses can provide valuable insight to the behavior and activity of future hurricanes. Knowing the behavior and patterns of the hurricanes, knowing what cities and regions are at the most risk from hurricane activity and how different factors play a role in hurricane activity can help people better prepare for hurricanes and minimize the losses caused by these storms. Meteorologists can use these predictions to better inform people about the route, severity of storms and what to expect as it passes. Governments can use this information to predict what cities will require the most aid. Insurance companies can use this data to decide what services are best suited to a specific location.

\newpage

# Background

\newpage

# Methodology

```{r}
#| echo: false
#libraries
library(zoo)
library(sf)
library(leaflet)
library(dplyr)
library(ggplot2)
```

```{r}
#| echo: false
#data collection and prep
hurdat2 = read.csv("hurdat2-1851-2023-051124.txt", header=F, as.is=T)

names(hurdat2) = c("DATE", "TIME_UTC", "POINT_TYPE", "STATUS", 
               "LATITUDE", "LONGITUDE", "WINDSPEED_KT", "PRESURE_MB", 
               "NE_34KT", "SE_34KT", "NW_34_KT", "SW_34_KT",
               "NE_50KT", "SE_50KT", "NW_50_KT", "SW_50_KT",
               "NE_64KT", "SE_64KT", "NW_64_KT", "SW_64_KT")

# this is the panel we need for the visualization
panel = cbind(HID = NA, HNAME = NA, hurdat2)

panel$HID = ifelse(grepl("AL|EP|CP", panel$DATE), panel$DATE, NA)

panel$HNAME = ifelse(grepl("AL|EP|CP", panel$DATE), panel$TIME_UTC, NA)

panel$HID = na.locf(panel$HID)

panel$HNAME = na.locf(panel$HNAME)

panel = panel[!grepl("AL|EP|CP", panel$DATE), ]


# these are the coordinates
panel$LATITUDE = trimws(panel$LATITUDE)
panel$LONGITUDE = trimws(panel$LONGITUDE)
panel$STATUS = trimws(panel$STATUS)

panel$LATITUDE = ifelse(grepl("S", panel$LATITUDE), paste0("-", panel$LATITUDE), panel$LATITUDE)
panel$LONGITUDE = ifelse(grepl("W", panel$LONGITUDE), paste0("-", panel$LONGITUDE), panel$LONGITUDE)

panel$LATITUDE = as.numeric(sub("N|S", "", panel$LATITUDE))
panel$LONGITUDE = as.numeric(sub("E|W", "", panel$LONGITUDE))


# gulf storms
gulf_storms = subset(panel, 
                    LATITUDE >= 18 & LATITUDE <= 30 & 
                    LONGITUDE >= -98 & LONGITUDE <= -80)

```

```{r}
#| results: asis
gulf_cities <- data.frame(
  City = c("New Orleans", "Houston", "Tampa", "Miami", "Corpus Christi", 
           "Pensacola", "Mobile", "Galveston", "Biloxi", "Key West",
           "Veracruz", "Tampico", "Campeche", "Cancún", "Mérida",
           "Ciudad del Carmen", "Progreso", "Coatzacoalcos", "Tuxpan", "Havana",
           "Varadero", "Cienfuegos", "Belize City", "George Town", "Nassau"),
  Country = c(rep("USA", 10), rep("Mexico", 9), rep("Cuba", 3), "Belize", "Cayman Islands", "Bahamas"),
  Latitude = c(30.0, 29.8, 28.0, 25.8, 27.8, 30.4, 30.7, 29.3, 30.4, 24.6,
               19.2, 22.2, 19.8, 21.2, 21.0, 18.7, 21.3, 18.1, 21.0, 23.1,
               23.2, 22.2, 17.5, 19.3, 25.0),
  Longitude = c(-90.1, -96.4, -82.5, -80.2, -97.4, -87.2, -88.0, -94.8, -88.9, -81.8,
                -96.1, -97.9, -90.5, -86.9, -89.6, -91.8, -89.7, -94.5, -97.4, -82.4,
                -81.2, -80.4, -88.2, -81.4, -77.4)
)

# boundaries for gulf of mexico region
gulf_bounds <- list(
  lat_min = min(gulf_cities$Latitude) - 1,  
  lat_max = max(gulf_cities$Latitude) + 1,
  lon_min = min(gulf_cities$Longitude) - 1,
  lon_max = max(gulf_cities$Longitude) + 1
)

gulf_storms <- subset(panel, 
                     LATITUDE >= gulf_bounds$lat_min & 
                     LATITUDE <= gulf_bounds$lat_max & 
                     LONGITUDE >= gulf_bounds$lon_min & 
                     LONGITUDE <= gulf_bounds$lon_max)


gulf_storms$YEAR <- as.numeric(substring(gulf_storms$DATE, 1, 4))
gulf_storms$MONTH <- as.numeric(substring(gulf_storms$DATE, 5, 6))


cat("Study Area Boundaries:\n")
cat("Latitude:", gulf_bounds$lat_min, "to", gulf_bounds$lat_max, "°N\n")
cat("Longitude:", gulf_bounds$lon_min, "to", gulf_bounds$lon_max, "°W\n")
cat("\nTotal storm observations:", nrow(gulf_storms))
cat("\nUnique storms:", length(unique(gulf_storms$HID)))
cat("\nDate range:", min(gulf_storms$DATE), "to", max(gulf_storms$DATE))

```

```{r}
# I will attempt to use leaflet correctly to create an interactive map
# Rendering this map is computationally expensive....

names(gulf_storms) <- ifelse(names(gulf_storms) == "" | is.na(names(gulf_storms)), paste0("V", seq_along(names(gulf_storms))), names(gulf_storms))

recent_gulf_storms <- gulf_storms %>%
  mutate(YEAR = as.numeric(substr(DATE, 1, 4))) %>%
  filter(YEAR >= 1999) %>%
  slice(seq(1, n(), by = 5))

leaflet(recent_gulf_storms) %>%
  addTiles() %>%
  setView(lng = -90, lat = 25, zoom = 5) %>%
  addCircleMarkers(
    lng = ~LONGITUDE,
    lat = ~LATITUDE,
    color = ~case_when(
      STATUS == "HU" ~ "red",
      STATUS == "TS" ~ "orange",
      TRUE ~ "blue"
    ),
    radius = 3,
    clusterOptions = markerClusterOptions(), # This line adds clustering to the points
    popup = ~paste(
      "Storm Name:", HNAME, "<br>",
      "Date:", DATE, "<br>",
      "Status:", STATUS, "<br>",
      "Wind Speed:", WINDSPEED_KT, "kt"
    )
  ) %>%
  addLegend(
    position = "bottomright",
    colors = c("red", "orange", "blue"),
    labels = c("Hurricane", "Tropical Storm", "Other"),
    title = "Storm Status"
  )


```

```{r}

yearly_storms <- recent_gulf_storms %>%
  group_by(YEAR) %>%
  summarize(storm_count = n())

View(yearly_storms)

monthly_storms <- recent_gulf_storms %>%
  mutate(MONTH = as.numeric(substr(DATE, 5, 6))) %>%
  group_by(MONTH) %>%
  summarize(storm_count = n())

View(monthly_storms)

status_count <- recent_gulf_storms %>%
  group_by(STATUS) %>%
  summarize(count = n())

View(status_count)

```

```{r}
ggplot(yearly_storms, aes(x = YEAR, y = storm_count)) +
  geom_line(color = "blue") +
  geom_point() +
  labs(title = "year storm count from 99-23",
       x = "Year",
       y = "# of Storms")

ggplot(monthly_storms, aes(x = MONTH, y = storm_count)) +
  geom_col(fill = "steelblue") +
  labs(title = "monthly storm freq",
       x = "Month",
       y = "# of Storms") +
  scale_x_continuous(breaks = 1:12,
                     labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", 
                                "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))

ggplot(status_count, aes(x = STATUS, y = count, fill = STATUS)) +
  geom_bar(stat = "identity") +
  labs(title = "strm count by status",
       x = "Status",
       y = "# of Storms") +
  scale_fill_manual(values = c("HU" = "red", "TS" = "orange", "TD" = "blue"))


intensity_trend <- recent_gulf_storms %>%
  group_by(YEAR) %>%
  summarize(avg_windspeed = mean(WINDSPEED_KT, na.rm = TRUE))

ggplot(intensity_trend, aes(x = YEAR, y = avg_windspeed)) +
  geom_line(color = "darkred") +
  geom_point() +
  labs(title = "Avg Storm Intensity Over Time 99-23",
       x = "Year",
       y = "Avg Wind Speed (kt)")



```

\newpage

# Findings

\newpage

# Conclusion

\newpage

# References {.unnumbered}

::: {#refs}
\[1\] National Oceanic and Atmospheric Administration. 2023. Hurricane Costs. NOAA, Office for Coastal Management. Retrieved October 16, 2024, from <https://coast.noaa.gov/states/fast-facts/hurricane-costs.html>\[1\] National Oceanic and Atmospheric Administration. 2023. Hurricane Costs. NOAA, Office for Coastal Management. Retrieved October 16, 2024, from <https://coast.noaa.gov/states/fast-facts/hurricane-costs.html>

\[2\] National Hurricane Center. 2023. Data Archive. NOAA, National Oceanic and Atmospheric Administration. Retrieved October 16, 2024, from <https://www.nhc.noaa.gov/data/>
:::
